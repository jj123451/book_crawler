import pytest
from unittest.mock import patch
from chunking_utility import chunk_text_with_overlaps, Chunk

# this test class was generated by AI (and it works pretty well)
class TestChunkTextWithOverlaps:
    
    @pytest.fixture
    def simple_text(self):
        """Simple text fixture for testing."""
        return "This is the first sentence. This is the second sentence. This is the third sentence."
    
    @pytest.fixture
    def single_sentence(self):
        """Single sentence fixture."""
        return "This is only one sentence."
    
    @pytest.fixture
    def empty_text(self):
        """Empty text fixture."""
        return ""
    
    @pytest.fixture
    def long_text(self):
        """Long text fixture for multiple chunk testing."""
        return (
            "Artificial intelligence is transforming our world. "
            "Machine learning algorithms process vast amounts of data. "
            "Neural networks can recognize patterns in complex datasets. "
            "Deep learning has revolutionized computer vision. "
            "Natural language processing enables computers to understand text. "
            "Robotics combines AI with physical systems. "
            "The future of AI holds many possibilities. "
            "Ethical considerations are important in AI development."
        )
    
    def test_simple_chunking_no_overflow(self, simple_text):
        """Test chunking where text fits in one chunk."""
        result = chunk_text_with_overlaps(simple_text, max_chunk_tokens=50, max_overlap_tokens=10)
        
        assert len(result) == 1
        assert isinstance(result[0], Chunk)
        assert result[0].before == ""
        assert result[0].main == simple_text
        assert result[0].after == ""
    
    def test_single_sentence(self, single_sentence):
        """Test with single sentence input."""
        result = chunk_text_with_overlaps(single_sentence, max_chunk_tokens=20, max_overlap_tokens=5)
        
        assert len(result) == 1
        assert result[0].before == ""
        assert result[0].main == single_sentence
        assert result[0].after == ""
    
    def test_empty_text(self, empty_text):
        """Test with empty text input."""
        result = chunk_text_with_overlaps(empty_text, max_chunk_tokens=10, max_overlap_tokens=5)
        
        assert len(result) == 0
    
    def test_chunking_with_multiple_chunks(self, long_text):
        """Test chunking that results in multiple chunks."""
        # Force small chunks to test multiple chunk scenario
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens=15, max_overlap_tokens=5)
        
        # Should have multiple chunks
        assert len(result) > 1
        
        # All results should be Chunk instances
        for chunk in result:
            assert isinstance(chunk, Chunk)
            assert isinstance(chunk.before, str)
            assert isinstance(chunk.main, str)
            assert isinstance(chunk.after, str)
    
    def test_first_chunk_properties(self, long_text):
        """Test properties of the first chunk."""
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens=15, max_overlap_tokens=5)
        
        if len(result) > 0:
            first_chunk = result[0]
            # First chunk should have empty before
            assert first_chunk.before == ""
            # First chunk should have non-empty main
            assert first_chunk.main != ""
    
    def test_last_chunk_properties(self, long_text):
        """Test properties of the last chunk."""
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens=15, max_overlap_tokens=5)
        
        if len(result) > 0:
            last_chunk = result[-1]
            # Last chunk should have empty after
            assert last_chunk.after == ""
            # Last chunk should have non-empty main
            assert last_chunk.main != ""
    
    def test_middle_chunk_properties(self, long_text):
        """Test properties of middle chunks."""
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens=15, max_overlap_tokens=5)
        
        if len(result) > 2:
            middle_chunk = result[1]  # Second chunk should be a middle chunk
            # Middle chunks should have non-empty before and after
            assert middle_chunk.before != ""
            assert middle_chunk.after != ""
            assert middle_chunk.main != ""
    
    def test_chunk_content_integrity(self, long_text):
        """Test that all original content is preserved across chunks."""
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens=20, max_overlap_tokens=5)
        
        # Combine all main content
        combined_main = " ".join([chunk.main for chunk in result])
        
        # The combined main content should contain all original sentences
        original_sentences = long_text.split(". ")
        for sentence in original_sentences:
            sentence_clean = sentence.replace(".", "").strip()
            if sentence_clean:  # Skip empty sentences
                assert sentence_clean in combined_main
    
    def test_token_limits_respected(self, long_text):
        """Test that token limits are approximately respected."""
        max_chunk_tokens = 20
        max_overlap_tokens = 5
        
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens, max_overlap_tokens)
        
        for chunk in result:
            # Count approximate tokens (simple word count)
            main_tokens = len(chunk.main.split())
            before_tokens = len(chunk.before.split()) if chunk.before else 0
            after_tokens = len(chunk.after.split()) if chunk.after else 0
            
            # Main chunk should not significantly exceed max_chunk_tokens
            # (allowing some flexibility due to sentence boundaries)
            assert main_tokens <= max_chunk_tokens + 10  # Some tolerance
            
            # Overlap sections should not exceed max_overlap_tokens
            assert before_tokens <= max_overlap_tokens + 5  # Some tolerance
            assert after_tokens <= max_overlap_tokens + 5  # Some tolerance
    
    def test_zero_overlap_tokens(self, simple_text):
        """Test behavior with zero overlap tokens."""
        result = chunk_text_with_overlaps(simple_text, max_chunk_tokens=20, max_overlap_tokens=0)
        
        for chunk in result:
            if len(result) == 1:
                # Single chunk case
                assert chunk.before == ""
                assert chunk.after == ""
    
    def test_large_overlap_tokens(self, simple_text):
        """Test behavior when overlap tokens exceed chunk tokens."""
        result = chunk_text_with_overlaps(simple_text, max_chunk_tokens=10, max_overlap_tokens=50)
        
        # Should still work without errors
        assert isinstance(result, list)
        for chunk in result:
            assert isinstance(chunk, Chunk)
    
    def test_very_small_chunk_size(self, simple_text):
        """Test with very small chunk size."""
        result = chunk_text_with_overlaps(simple_text, max_chunk_tokens=5, max_overlap_tokens=2)
        
        # Should create multiple small chunks
        assert len(result) > 1
        for chunk in result:
            assert isinstance(chunk, Chunk)
    
    def test_sentence_boundary_preservation(self, long_text):
        """Test that sentence boundaries are preserved."""
        result = chunk_text_with_overlaps(long_text, max_chunk_tokens=25, max_overlap_tokens=8)
        
        for chunk in result:
            # Main content should contain complete sentences
            if chunk.main.strip():
                # Should end with sentence ending punctuation or be a complete thought
                main_sentences = chunk.main.split('. ')
                # Check that we're not cutting sentences mid-way (basic check)
                for sentence in main_sentences[:-1]:  # All but last should end properly
                    if sentence.strip():
                        # Should be reasonable sentence length (basic sanity check)
                        assert len(sentence.strip()) > 3
    
    def test_text_with_special_characters(self):
        """Test with text containing special characters and punctuation."""
        special_text = "Hello, world! How are you? I'm fine. What about you?"
        result = chunk_text_with_overlaps(special_text, max_chunk_tokens=15, max_overlap_tokens=3)
        
        assert isinstance(result, list)
        for chunk in result:
            assert isinstance(chunk, Chunk)
    
    def test_nltk_tokenization_mock(self):
        """Test behavior when NLTK functions are mocked."""
        with patch('chunking_utility.sent_tokenize') as mock_sent_tokenize, \
             patch('chunking_utility.word_tokenize') as mock_word_tokenize:
            
            mock_sent_tokenize.return_value = ["Sentence one.", "Sentence two."]
            mock_word_tokenize.side_effect = lambda x: x.split()
            
            result = chunk_text_with_overlaps("Sentence one. Sentence two.", 
                                            max_chunk_tokens=10, max_overlap_tokens=3)
            
            assert isinstance(result, list)
            mock_sent_tokenize.assert_called_once()
    
    def test_return_type_and_structure(self, simple_text):
        """Test that return type and structure are correct."""
        result = chunk_text_with_overlaps(simple_text, max_chunk_tokens=20, max_overlap_tokens=5)
        
        # Should return a list
        assert isinstance(result, list)
        
        # Each item should be a Chunk
        for chunk in result:
            assert isinstance(chunk, Chunk)
            assert hasattr(chunk, 'before')
            assert hasattr(chunk, 'main')
            assert hasattr(chunk, 'after')
            assert isinstance(chunk.before, str)
            assert isinstance(chunk.main, str)
            assert isinstance(chunk.after, str)
    
    def test_edge_case_single_long_sentence(self):
        """Test with a single sentence that exceeds max_chunk_tokens."""
        long_sentence = "This is an extremely long sentence that contains many words and definitely exceeds the maximum token limit that we have set for testing purposes."
        
        result = chunk_text_with_overlaps(long_sentence, max_chunk_tokens=5, max_overlap_tokens=2)
        
        # Should still return at least one chunk
        assert len(result) >= 1
        # The main content should contain the sentence (even if it exceeds limits)
        assert "extremely long sentence" in result[0].main


# Parametrized tests for different chunk and overlap combinations
@pytest.mark.parametrize("max_chunk_tokens,max_overlap_tokens", [
    (10, 3),
    (20, 5),
    (50, 10),
    (5, 15),  # overlap > chunk
    (100, 0),  # no overlap
])
def test_various_token_combinations(max_chunk_tokens, max_overlap_tokens):
    """Test various combinations of chunk and overlap token limits."""
    text = "First sentence here. Second sentence follows. Third sentence comes next. Fourth sentence ends."
    
    result = chunk_text_with_overlaps(text, max_chunk_tokens, max_overlap_tokens)
    
    assert isinstance(result, list)
    for chunk in result:
        assert isinstance(chunk, Chunk)
        assert isinstance(chunk.before, str)
        assert isinstance(chunk.main, str)
        assert isinstance(chunk.after, str)


@pytest.mark.parametrize("text,expected_chunks", [
    ("Single sentence.", 1),
    ("", 0),
    ("One. Two.", 1),  # Likely fits in one chunk with reasonable limits
])
def test_expected_chunk_counts(text, expected_chunks):
    """Test expected number of chunks for known inputs."""
    result = chunk_text_with_overlaps(text, max_chunk_tokens=30, max_overlap_tokens=5)
    assert len(result) == expected_chunks


if __name__ == '__main__':
    pytest.main([__file__, '-v'])